{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Infrastructure for the cluster setup\n",
      "Code and info needs to be packaged and transfered back and fourth between the cluster and the local machine."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Setup scripts in python\n",
      "\n",
      "+ [EXISTS] Script that generates the suite of input files (make_batch_input.py or something similar)\n",
      "+ [NEEDS UPDATING] Script that launches the batch processing of input files --> fortran program --> output files\n",
      "+ [NEEDS UPDATING] Script to parse each simulation into individual timesteps &etc.\n",
      "+ [UNMADE] package that info for collection/transfer to the master node (zip, gzip, etc)\n",
      "+ [UNMADE] package batch run info for transfer from the master node to more permanent storage (EBS, local machine... something.)\n",
      "\n",
      "## AWS 'hardware' setup\n",
      "\n",
      "+ Want to create an EBS volume to store the scripts above and the fortran files\n",
      "+ Figure out how to add persistant EBS volumes to cluster setup\n",
      "\n",
      "-----\n",
      "\n",
      "Test as much of this out on my local machine as possible beforehand.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Local machine testing\n",
      "\n",
      "1. [DONE] Start 2-engine cluster \n",
      "2. [DONE] Open a python notebook session and connect it to the cluster client\n",
      "3. [DONE] Remind myself (and record it here) what the dependency chain(s) is for the python batch parsing scripts\n",
      "4. Change batch_commands.py to use the cluster/load balanced view approach to parallelization, rather than the multiproccessing module.\n",
      "5. [DONE] Find a single, good input testcase for the fortran program (for initial testing on the AWS cluster)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Steps 1 and 2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = Client()\n",
      "def checkhostname():\n",
      "    import socket\n",
      "    return socket.gethostname()\n",
      "\n",
      "balanced       = c.load_balanced_view()\n",
      "direct         = c[:]\n",
      "balanced.block = True\n",
      "direct.block   = True\n",
      "\n",
      "hostnames = direct.apply(checkhostname)\n",
      "hostnames"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "['MachoMac-2.local', 'MachoMac-2.local']"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Step 3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load  /Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai/python_scripts/update_index.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#============================================================\n",
      "# Import modules\n",
      "#============================================================\n",
      "import re, os, fnmatch, sys, easygui as eg\n",
      "from numpy import *\n",
      "from matplotlib import * \n",
      "from pylab import *\n",
      "import asciitable, string, datetime, shutil, atpy\n",
      "\n",
      "#============================================================\n",
      "# Define useful functions\n",
      "#============================================================\n",
      "def modification_date(filename):\n",
      "    #    t = os.path.getmtime(filename)\n",
      "    t = filename.split('/')\n",
      "    index = 2 + t.index(filter(lambda x:x.startswith('201'),t)[0])\n",
      "    t = t[index]\n",
      "    return datetime.datetime.strptime(t,'%B_%d_%Y')\n",
      "#============================================================\n",
      "def extract_value(line,key,splitval):\n",
      "    loc = line.find(key) + len(key)\n",
      "    line = line[loc:]\n",
      "    loc = line.find(splitval) + len(splitval)\n",
      "    line = line[loc:]\n",
      "    val = line.split()[0]\n",
      "    return val\n",
      "#============================================================\n",
      "def get_update_list(base_path=''):\n",
      "    if base_path == '':\n",
      "        base_path = eg.diropenbox(msg='Select directory to crawl',default ='/Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai/outputs/2013/')         \n",
      "        #    result = []\n",
      "    for (path,dirs,files) in os.walk(base_path):\n",
      "        if 'full_run_output.txt' in files:\n",
      "            update_index_main(path)\n",
      "            #      result.append(path)    \n",
      "    return 0\n",
      "\n",
      "#============================================================\n",
      "# Main function\n",
      "#============================================================\n",
      "def update_index_main(dirname=''):\n",
      "    # Declare variables relevant to the index file\n",
      "    path_to_index_file = '/Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai/outputs/SIMULATION_INDEX.txt'\n",
      "    header = ['DateCreated','Path','STARTING MODEL','BINARY OUTPUT FILE','MODA','NMOD','NRIT','ITMN','ITMX','JADD','JSUB','NATM','Atmx','Atmn','dTAX','L/H','dLmx','dLmn','dXmx','dXmn','dPmx','dPmn','Crad','Cwrk','dZmx','dZmn','dZdt','epsP','epsR','epsL','epsT','SminP','SminR','SminL','SminT','SmaxP','SmaxR','SmaxL','SmaxT','dTIM','FACT','dTMN','dTMX','CHMN','CHMX','XX','YY', 'JNOU', 'SIGM', 'KZPE', 'ZSTA', 'ECCN', 'SEMI', 'VALN', 'QVAL','Zmass','TMAX','TWRT']\n",
      "\n",
      "    header_val = {}\n",
      "    for item in header:\n",
      "        header_val[item] = 'NaN'\n",
      "\n",
      "    # Check if the index file exists.  If not, create it.\n",
      "    if (os.path.isfile(path_to_index_file) == False):\n",
      "        # Make the file\n",
      "        index_file = open(path_to_index_file,'w')\n",
      "        index_file.write(string.join(header,'\\t'))\n",
      "        index_file.write('\\n')\n",
      "    # Otherwise, open the existing index file in write/append mode\n",
      "    else:\n",
      "        index_file = open(path_to_index_file,'a')\n",
      "\n",
      "    # If an input filename wasn't provided, prompt the user to select one:\n",
      "    if (dirname == ''):\n",
      "        # Ask the user which result to parse and add to the index\n",
      "        name_of_file_to_add = eg.diropenbox(msg='Which run do you want to add to the index?',default ='/Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai/outputs/') \n",
      "    else:\n",
      "        name_of_file_to_add = dirname\n",
      "\n",
      "\n",
      "    # Get the DateCreated and Path values for this file\n",
      "    date_run_was_created = modification_date(name_of_file_to_add)\n",
      "    ##########\n",
      "    header_val['DateCreated'] = date_run_was_created.strftime('%Y-%m-%d')\n",
      "    ##########\n",
      "    run_path = name_of_file_to_add\n",
      "\n",
      "    # Open the run file for parsing\n",
      "    file_to_add = open(name_of_file_to_add+'/full_run_output.txt','r')\n",
      "    header_val['Path'] = name_of_file_to_add\n",
      "    stop_string = 'COMRD: END OF INPUT DATA'\n",
      "\n",
      "    # Read the input params (file header, sort of), and parse them\n",
      "    for line in file_to_add:\n",
      "        # Ignore comment lines in the input file\n",
      "        if (line.find('*') > -1):\n",
      "            continue\n",
      "        # Stop reading in the file once you reach the designated stopping point\n",
      "        elif (line.find(stop_string) > -1):\n",
      "            break\n",
      "        else:\n",
      "            #------------------------------------------------\n",
      "            ## Special Parsing Cases ##\n",
      "            #------------------------------------------------\n",
      "            # If the line contains input or output file info, parse like this:\n",
      "            if (line.find(header[2]) > -1 ):\n",
      "                header_val[header[2]] = re.split(':\\s+[0-9]+',line.strip())[-1].split()[-1]        \n",
      "            elif (line.find(header[3]) > -1):\n",
      "                header_val[header[3]] = re.split(':\\s+[0-9]+',line.strip())[-1].split()[-1]\n",
      "                \n",
      "            # If the line contains SMIN or SMAX file info, parse like this:\n",
      "            elif (line.find('SMIN') > -1):\n",
      "                foo = line.split('=')[-1].split()\n",
      "                for i in range(4):\n",
      "                    header_val[header[31+i]] = foo[i]\n",
      "            elif (line.find('SMAX') > -1):\n",
      "                foo = line.split('=')[-1].split()\n",
      "                for i in range(4):\n",
      "                    header_val[header[35+i]] = foo[i]\n",
      "\n",
      "            #------------------------------------------------\n",
      "            ## Normal Parsing Case ##\n",
      "            #------------------------------------------------\n",
      "            else:\n",
      "                for item in header:\n",
      "                    if (line.find(item) > -1):\n",
      "                        foo = extract_value(line,item,'=')\n",
      "                        header_val[item] = foo\n",
      "\n",
      "                \n",
      "        # Close the input params file\n",
      "    file_to_add.close()  \n",
      "\n",
      "    # Get the dictionary entries in the right (header) order, and convert the values to a single line/string.\n",
      "    foo = []\n",
      "    for item in header:\n",
      "        foo.append(header_val[item])\n",
      "    foo = string.join(foo,'\\t')\n",
      "\n",
      "    # Write the run info to the index file\n",
      "    index_file.write(foo+'\\n')\n",
      "\n",
      "    # Have something here that eliminates duplicates from the full_data index...?\n",
      "    # May want to have a seperate program for doing that...\n",
      "\n",
      "    # Close the index file\n",
      "    index_file.close()\n",
      "    return 0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load /Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai/python_scripts/parse_kozai_results.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#============================================================\n",
      "# Import modules\n",
      "#============================================================\n",
      "import re, os, fnmatch, sys, easygui as eg\n",
      "import numpy, matplotlib, pylab\n",
      "import asciitable, string, datetime, shutil, atpy\n",
      "from update_index import *\n",
      "#============================================================\n",
      "\n",
      "def parse_results(SourceFile=''):\n",
      "    #============================================================\n",
      "    # Determine where to store the results\n",
      "    #============================================================\n",
      "    date = datetime.datetime.today()\n",
      "    month = date.strftime(\"%B\")\n",
      "    day = date.strftime(\"%d\")\n",
      "    year = date.strftime(\"%Y\")\n",
      "    secPerYear = 3600.0 * 24.0 * 365.0\n",
      "\n",
      "    homedir = os.getcwd()\n",
      "    savedirBase = \"/Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai/outputs/\"+year+\"/\"+month+\"/\"+month+\"_\"+day+\"_\"+year+\"/\"\n",
      "    tmp = [0]\n",
      "    versionNum=[0]\n",
      "\n",
      "    if not os.path.exists(savedirBase): # If the save-directory does not already exist, create it\n",
      "        os.makedirs(savedirBase)\n",
      "    else:  # See how many versions, if any, have already been written here\n",
      "        filelist = [ ]\n",
      "        for file in os.listdir(savedirBase):\n",
      "            if fnmatch.fnmatch(file,'*v[0-9]*'):\n",
      "                filelist.append(file)\n",
      "                # See how many versions already exist\n",
      "            for name in filelist:\n",
      "                prefix = string.split(name,'v')\n",
      "                tmp.append(int(prefix[1]))\n",
      "    \n",
      "    # Figure out which version number we're writing to file, now\n",
      "    versionNum = str(max(tmp)+1)\n",
      "    \n",
      "    # Make the directory for our current version\n",
      "    savedirBase = savedirBase+\"v\"+versionNum+\"/\"\n",
      "    os.makedirs(savedirBase)\n",
      "    \n",
      "    # Copy the full run results file to that directory\n",
      "    if SourceFile == '':\n",
      "        SourceFile =  eg.fileopenbox(msg='Select the file you want to parse',default='/Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai/outputs/')\n",
      "\n",
      "    shutil.move(SourceFile,savedirBase+'full_run_output.txt')\n",
      "\n",
      "    # Move into the savedirBase folder\n",
      "    os.chdir(savedirBase)\n",
      "\n",
      "    InModel = 0\n",
      "    InAtmos = 0\n",
      "    currentTime = ''\n",
      "    # model number, time, top of atmos radius, top of atmos luminosity, top of atmos temperature\n",
      "    atmosOutFile = open('atmos_data.txt','w')\n",
      "    atmosOutFile.write('ModelNum    Time    R     L     Teff\\n')\n",
      "    atmosOutFile.close()\n",
      "    \n",
      "    # Go through the full run outputs file\n",
      "    infile = open(\"full_run_output.txt\",'r')\n",
      "    for line in infile:\n",
      "        # Skip over blank lines\n",
      "        if (line == \"\\n\"):\n",
      "            continue  \n",
      "        # Find the kozai timescale for this run\n",
      "        if (line.find('KZPE') != -1):\n",
      "            tKozai = float(line.split()[1]) * secPerYear\n",
      "        # Find the start of each model\n",
      "        if (line.find('Start of model') != -1):\n",
      "            InModel = 1\n",
      "            # Figure out which model number this one is\n",
      "            modelNum = line.split()[-1]\n",
      "            modelOutFile = open('model_'+modelNum+'.txt','w')\n",
      "            continue\n",
      "        # Find the end of each model\n",
      "        if (line.find('End of model') != -1):\n",
      "            InModel = 0\n",
      "            modelOutFile.close()\n",
      "            continue\n",
      "        # Find the start of each atmos\n",
      "        if (line.find('Start of atmos') != -1):\n",
      "            InAtmos = 1\n",
      "            atmosNum = line.split()[-1]\n",
      "            atmosOutFile = open('atmos_data.txt','a')\n",
      "            continue\n",
      "        # Find the end of each atmos\n",
      "        if (line.find('End of atmos') != -1):\n",
      "            InAtmos=0\n",
      "            atmosOutFile.close()\n",
      "            continue\n",
      "    \n",
      "        # Write the model data to its own file\n",
      "        if (InModel == 1):\n",
      "            if (line.find('TIME:') != -1):\n",
      "                currentTime= line.split('TIME:')[-1].split()[0]\n",
      "                continue\n",
      "            else:\n",
      "                # Strip out the 'are we convecting?' asterisks\n",
      "                line = line.replace('*','')\n",
      "                modelOutFile.write(line)\n",
      "    \n",
      "        # Write the atmos data to... its own file?  Or collate results in a single file?\n",
      "        if (InAtmos == 1) and (line.find('Top') != -1):\n",
      "            # Manipulate/parse the line string to extract/refashion its content for\n",
      "            # printing to the atmos output file\n",
      "            foo = line.split(\":\")[-1].split()\n",
      "            Teff = foo[1]\n",
      "            R = foo[3]\n",
      "            L = foo[5]\n",
      "            # We want the following info, in this order:\n",
      "            # model number, time, top of atmos radius, top of atmos luminosity, top of atmos temperature\n",
      "            currentTime.replace('D','E')\n",
      "            print 'currentTime is ',currentTime\n",
      "            currentTime = str(float(currentTime)/tKozai)\n",
      "            print 'currentTime is ',currentTime            \n",
      "            print ' '\n",
      "            line = atmosNum+'    '+currentTime+'    '+R+'     '+L+'      '+Teff+'\\n'\n",
      "    \n",
      "            # Write the line to file\n",
      "            atmosOutFile.write(line)\n",
      "    \n",
      "    \n",
      "    # Change back to the original directory    \n",
      "    os.chdir(homedir)\n",
      "    \n",
      "    # Update the simulation index with this run's info\n",
      "    #run update_index.py\n",
      "    print 'Updating the index file'\n",
      "    foo = update_index_main(savedirBase)\n",
      "\n",
      "    return 0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named update_index",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-17-60da30fd3463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpylab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masciitable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mupdate_index\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#============================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: No module named update_index"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ERROR: ImportError: No module named update_index [IPython.core.interactiveshell]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load /Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai/python_scripts/batch_commands.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################################\n",
      "# NOTE: YOU NEED TO COPY AND PASTE THESE\n",
      "# FUNCTIONS DIRECTLY INTO THE PYTHON TERMINAL\n",
      "# WINDOW.\n",
      "#\n",
      "# Typing 'run batch_commands.py'\n",
      "# doesn't work because of some sort of issue\n",
      "# with importing and using the os module.\n",
      "###############################################\n",
      "\n",
      "#----------------------------------------------\n",
      "from parse_kozai_results import parse_results\n",
      "from multiprocessing import Pool\n",
      "#from os import *\n",
      "import os\n",
      "\n",
      "#----------------------------------------------\n",
      "def batch_parse(num_runs=0):\n",
      "    if num_runs == 0:\n",
      "        print 'You fool!  You need to tell me how many runs there are to parse!'\n",
      "        return 1\n",
      "    else:\n",
      "        batch_output_dir = '/Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai/outputs/batch_outputs/'\n",
      "        for i in range(1,num_runs+1,1):\n",
      "            file_to_parse = batch_output_dir+'run'+str(i)+'.txt'\n",
      "            parse_results(file_to_parse)\n",
      "            print 'Parsed ',file_to_parse\n",
      "        return 0\n",
      "    \n",
      "#----------------------------------------------\n",
      "def simulation_syscall(input_filename=''):\n",
      "    #    os.system(\"echo \"+foo)\n",
      "    homedir = os.getcwd()\n",
      "    outdir = '/Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai/outputs/batch_outputs/'\n",
      "    indir = '/Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai/inputs/batch_inputs/'\n",
      "    rundir = '/Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai'\n",
      "\n",
      "    filename_base = input_filename.split('/')[-1]\n",
      "    output_filename = outdir+filename_base\n",
      "    input_filename = indir+filename_base\n",
      "\n",
      "    os.chdir(rundir)\n",
      "    #    os.system(\"./full_tidal_heating < \"+input_filename+\" > \"+output_filename)\n",
      "    os.system(\"./full_tidal_heating_time_limited < \"+input_filename+\" > \"+output_filename)\n",
      "    #    os.system(\"growlnotify -m  \\\" \"+output_filename + \" completed\\\" -s \\\"Background script notification\\\" &\")\n",
      "    print 'Done running '+input_filename+\" simulation.\"\n",
      "    foo = output_filename.split('.txt')[-1]+'.mod'\n",
      "    os.system(\"rm \"+input_filename+\" \"+foo)\n",
      "    os.chdir(homedir)\n",
      "    print filename_base\n",
      "    \n",
      "    return filename_base\n",
      "\n",
      "#----------------------------------------------\n",
      "def batch_run(num_proc=6):\n",
      "    pool = Pool(num_proc)\n",
      "    indir = '/Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai/inputs/batch_inputs/'\n",
      "\n",
      "    files = os.listdir(indir)\n",
      "    pool.map(simulation_syscall,files)\n",
      "    pool.close()\n",
      "    pool.join()\n",
      "\n",
      "    num = len(files)\n",
      "    batch_parse(num)\n",
      "\n",
      "    \n",
      "    #   print 'Done with this simulation batch run!'\n",
      "    return 0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "----\n",
      "##Step 5\n",
      "\n",
      "Test case input:\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "/Volumes/Data/Work/Research/BodenheimerCode/Code_for_Kozai/inputs/test_for_time_limited_tidal_calcs.txt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(Not 100% sure about this, but will test it out on local machine first.)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}